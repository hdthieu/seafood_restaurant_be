// src/modules/rag/rag.service.ts
import { Injectable, Logger } from "@nestjs/common";
import { QdrantClient } from "@qdrant/js-client-rest";
import { LlmGateway } from "../ai/llm.gateway";
import { GatewayEmbeddings } from "./langchain-embeddings";
import { QdrantVectorStore } from "@langchain/qdrant";
import { Document } from "@langchain/core/documents";
export type RagRole = "KITCHEN" | "WAITER" | "CASHIER" | "MANAGER" | "ALL";
export type RagHit = {
  text: string;
  score?: number;
  source?: string;
  absPath?: string;
  index?: number;
};

@Injectable()
export class RagService {
  private readonly log = new Logger("RAG");
  private readonly qdrant = new QdrantClient({
    url: process.env.QDRANT_URL || "http://localhost:6333",
    apiKey: process.env.QDRANT_API_KEY || undefined,
  });

  // collection schema
  private readonly schemaCollection =
    process.env.QDRANT_SCHEMA_COLLECTION || "restaurant_schema";

  // collection SOP/docs
  private readonly docCollection =
    process.env.QDRANT_DOC_COLLECTION || "restaurant_docs";

  constructor(private readonly llm: LlmGateway) {}

  // ========== EMBEDDINGS / COLLECTION ==========

  private async embed(input: string | string[]) {
    return this.llm.embed(input);
  }

  private async getEmbedDim(): Promise<number> {
    const v = await this.embed("probe");
    const arr = Array.isArray(v) && Array.isArray((v as any)[0])
      ? (v as number[][])[0]
      : (v as number[]);
    if (!arr?.length) throw new Error("Cannot infer embedding dimension");
    return arr.length;
  }

  private async ensureCollection(collection: string): Promise<number> {
    const dim = await this.getEmbedDim();

    try {
      const info: any = await this.qdrant.getCollection(collection as any);
      const currentDim =
        info?.result?.config?.params?.vectors?.size ??
        info?.config?.params?.vectors?.size ??
        info?.result?.config?.params?.vectors?.["float"]?.size ??
        null;

      if (currentDim && currentDim !== dim) {
        if (String(process.env.RAG_RESET || "0") !== "1") {
          throw new Error(
            `'${collection}' size=${currentDim}, embed=${dim}. Set RAG_RESET=1 to recreate.`,
          );
        }
        this.log.warn(`Recreating '${collection}' with size=${dim} ...`);
        await this.qdrant.deleteCollection(collection as any);
      }
    } catch (_) {}

    try {
      await this.qdrant.createCollection(collection as any, {
        vectors: { size: dim, distance: "Cosine" },
      } as any);
    } catch (e: any) {
      const conflict = e?.status === 409 || /exists/i.test(e?.message || "");
      if (!conflict) throw e;
    }

    return dim;
  }

  // ========== UPSERT ==========

  async upsertSchemaChunk(ch: { id: string; text: string; meta?: any }) {
    await this.ensureCollection(this.schemaCollection);
    const v = await this.embed(ch.text);
    const vector = this.normalizeVector(v);

    const meta = ch.meta || {};

    await this.qdrant.upsert(this.schemaCollection, {
      wait: true,
      points: [
        {
          id: ch.id,
          vector,
          payload: {
            text: ch.text,
            ...meta,
            page_content: ch.text,
            pageContent: ch.text,
            metadata: { ...meta },
          },
        },
      ],
    });
  }

  async upsertDocChunk(ch: { id: string; text: string; meta?: any }) {
    await this.ensureCollection(this.docCollection);
    await this.ensureDocPayloadIndexes();

    const v = await this.embed(ch.text);
    const vector = this.normalizeVector(v);

    await this.qdrant.upsert(this.docCollection as any, {
      wait: true,
      points: [
        {
          id: ch.id,
          vector,
          payload: {
            page_content: ch.text,
            metadata: {
              ...(ch.meta || {}),
            },
          },
        },
      ],
    });
  }

  private normalizeVector(v: any): number[] {
    if (Array.isArray(v)) {
      if (Array.isArray(v[0])) {
        return v[0] as number[];
      }
      return v as number[];
    }
    throw new Error("Embedding vector is invalid");
  }

  // ========== RAW SEARCH (Qdrant REST) ==========

  async searchDocs(
    question: string,
    topK = Number(process.env.RAG_TOPK || 16),
    scoreThreshold = Number(process.env.RAG_SCORE_THRESHOLD || 0.05),
    filter?: any,
  ) {
    await this.ensureCollection(this.docCollection);
    await this.ensureDocPayloadIndexes();

    const v = await this.embed(question);
    const vector = this.normalizeVector(v);

    const r = await this.qdrant.search(this.docCollection as any, {
      vector,
      limit: topK,
      with_payload: true,
      filter,
    });

    const hits = (r || []) as Array<{
      score?: number;
      payload?: any;
    }>;

    return hits
      .filter((h) => (h.score ?? 0) >= scoreThreshold)
      .sort((a, b) => (b.score ?? 0) - (a.score ?? 0));
  }

  async query(
    question: string,
    topK = Number(process.env.RAG_TOPK || 16),
    scoreThreshold?: number,
  ): Promise<RagHit[]> {
    const threshold =
      typeof scoreThreshold === "number"
        ? scoreThreshold
        : Number(process.env.RAG_SCORE_THRESHOLD || 0.18);

    const hits = await this.searchDocs(question, topK, threshold);

    return (hits || []).map((h: any) => {
      const meta = (h.payload?.metadata || {}) as any;

      return {
        text:
          (h.payload?.page_content as string) ||
          (meta.text as string) ||
          "",
        score: h.score,
        source: meta.source,
        absPath: meta.absPath,
        index: meta.index,
      };
    });
  }

  // ========== RAG.ask (LLM t√≥m t·∫Øt) ==========

  async ask(question: string, topK = Number(process.env.RAG_TOPK || 4)) {
    const hits = await this.query(question, topK);

    const context = hits
      .map(
        (h, i) =>
          `[${i + 1}] (${(h.score || 0).toFixed(3)}) ${h.source || ""}\n${h.text}`,
      )
      .join("\n\n---\n\n");

   const sys = `
B·∫°n l√† tr·ª£ l√Ω n·ªôi b·ªô c·ªßa nh√† h√†ng.

NHI·ªÜM V·ª§:
- Ch·ªâ d·ª±a v√†o ph·∫ßn "T√†i li·ªáu" ƒë·ªÉ tr·∫£ l·ªùi.
- Tr·∫£ l·ªùi NG·∫ÆN G·ªåN, ƒë√∫ng TR·ªåNG T√ÇM c√¢u h·ªèi.
- N·∫øu c√¢u h·ªèi d·∫°ng "quy tr√¨nh", "c√°c b∆∞·ªõc", "workflow":
  ‚Üí Tr·∫£ l·ªùi theo d·∫°ng:
    1) ...
    2) ...
    3) ...
- N·∫øu t√†i li·ªáu c√≥ th√¥ng tin li√™n quan, B·∫ÆT BU·ªòC ph·∫£i d√πng ƒë·ªÉ tr·∫£ l·ªùi.
- Ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi ƒë√∫ng 1 c√¢u:
  "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu."
  khi th·∫≠t s·ª± KH√îNG c√≥ th√¥ng tin li√™n quan N√ÄO trong to√†n b·ªô t√†i li·ªáu.

Tr·∫£ l·ªùi ti·∫øng Vi·ªát th√¢n thi·ªán, r√µ r√†ng.
`.trim();


    const usr = `C√¢u h·ªèi: ${question}\n\nT√†i li·ªáu:\n${context || "(tr·ªëng)"}`;

    let answer = "";
    try {
      answer = (await this.llm.chat(sys, usr, 28_000)) || "";
    } catch (e) {
      this.log.warn(
        `[RAG.ask] llm.chat error: ${
          e instanceof Error ? e.message : e
        }`,
      );
    }

    if ((!answer || !answer.trim()) && hits.length > 0) {
      this.log.warn(
        `[RAG.ask] LLM kh√¥ng tr·∫£ l·ªùi, d√πng fallback t·ª´ context. hits=${hits.length}`,
      );
      answer =
        "D∆∞·ªõi ƒë√¢y l√† n·ªôi dung t√†i li·ªáu li√™n quan m√† h·ªá th·ªëng t√¨m ƒë∆∞·ª£c:\n\n" +
        context;
    }

    if ((!answer || !answer.trim()) && hits.length === 0) {
      answer = "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu.";
    }

    return {
      answer: answer.trim(),
      sources: hits.map((h, i) => ({
        index: i + 1,
        score: h.score,
        source: h.source,
      })),
    };
  }

  // ========== PAYLOAD INDEXES ==========

  private async ensureDocPayloadIndexes() {
    try {
      await this.qdrant.createPayloadIndex(this.docCollection as any, {
        field_name: "metadata.role",
        field_schema: "keyword",
      } as any);
      this.log.log("[RAG] Created payload index for metadata.role");
    } catch (e: any) {
      if (!/already exists/i.test(e?.message || "")) {
        this.log.warn(
          `[RAG] createPayloadIndex(metadata.role) error: ${
            e?.message || e
          }`,
        );
      }
    }

    try {
      await this.qdrant.createPayloadIndex(this.docCollection as any, {
        field_name: "metadata.source",
        field_schema: "keyword",
      } as any);
      this.log.log("[RAG] Created payload index for metadata.source");
    } catch (e: any) {
      if (!/already exists/i.test(e?.message || "")) {
        this.log.warn(
          `[RAG] createPayloadIndex(metadata.source) error: ${
            e?.message || e
          }`,
        );
      }
    }
  }

  async resetDocCollection() {
    this.log.warn(`[RAG] Deleting collection ${this.docCollection} ...`);
    try {
      await this.qdrant.deleteCollection(this.docCollection as any);
    } catch (e: any) {
      this.log.warn(
        `[RAG] deleteCollection(doc) error: ${e?.message || e}`,
      );
    }
    await this.ensureCollection(this.docCollection);
    this.log.warn(`[RAG] Doc collection recreated.`);
  }

  async resetSchemaCollection() {
    this.log.warn(
      `[RAG] Deleting collection ${this.schemaCollection} ...`,
    );
    try {
      await this.qdrant.deleteCollection(this.schemaCollection as any);
    } catch (e: any) {
      this.log.warn(
        `[RAG] deleteCollection(schema) error: ${
          e?.message || e
        }`,
      );
    }
    await this.ensureCollection(this.schemaCollection);
    this.log.warn(`[RAG] Schema collection recreated.`);
  }

  // ========== LangChain VectorStore ==========

  private lcEmbeddings?: GatewayEmbeddings;
  private lcVectorStore?: QdrantVectorStore;

  private async getVectorStore() {
    if (this.lcVectorStore) return this.lcVectorStore;

    this.lcEmbeddings = new GatewayEmbeddings(this.llm);

    this.lcVectorStore =
      await QdrantVectorStore.fromExistingCollection(
        this.lcEmbeddings,
        {
          url: process.env.QDRANT_URL || "http://localhost:6333",
          apiKey: process.env.QDRANT_API_KEY || undefined,
          collectionName: this.docCollection,
          contentPayloadKey: "page_content",
          metadataPayloadKey: "metadata",
        },
      );

    return this.lcVectorStore;
  }

  // ========== Query Expansion (kh√¥ng √©p file) ==========

  private buildEnrichedQuestion(question: string): string {
    const q = question.toLowerCase();
    const keywords: string[] = [];

    // Khi·∫øu n·∫°i kh√°ch
    if (
      q.includes("khi·∫øu n·∫°i") ||
      q.includes("khieu nai") ||
      q.includes("ph√†n n√†n") ||
      q.includes("phan nan") ||
      q.includes("complain")
    ) {
      keywords.push(
        "khi·∫øu n·∫°i kh√°ch",
        "ph√†n n√†n c·ªßa kh√°ch",
        "x·ª≠ l√Ω ph√†n n√†n",
        "quy tr√¨nh x·ª≠ l√Ω khi·∫øu n·∫°i",
        "kh√°ch kh√¥ng h√†i l√≤ng",
      );
    }

    // Gi·ªù gi·∫•c / ch·∫•m c√¥ng
    if (
      q.includes("gi·ªù gi·∫•c") ||
      q.includes("gio giac") ||
      q.includes("ƒëi tr·ªÖ") ||
      q.includes("di tre") ||
      q.includes("v·ªÅ s·ªõm") ||
      q.includes("ve som") ||
      q.includes("ch·∫•m c√¥ng") ||
      q.includes("cham cong")
    ) {
      keywords.push(
        "quy ƒë·ªãnh gi·ªù gi·∫•c l√†m vi·ªác",
        "ƒëi tr·ªÖ v·ªÅ s·ªõm",
        "n·ªôi quy ch·∫•m c√¥ng",
        "quy ƒë·ªãnh ch·∫•m c√¥ng",
      );
    }

    // Th∆∞·ªüng ph·∫°t / k·ª∑ lu·∫≠t
    if (
      q.includes("th∆∞·ªüng ph·∫°t") ||
      q.includes("thuong phat") ||
      q.includes("k·ª∑ lu·∫≠t") ||
      q.includes("ky luat") ||
      q.includes("khen th∆∞·ªüng") ||
      q.includes("khen thuong")
    ) {
      keywords.push(
        "quy ƒë·ªãnh th∆∞·ªüng ph·∫°t",
        "n·ªôi quy k·ª∑ lu·∫≠t",
        "quy ƒë·ªãnh khen th∆∞·ªüng",
        "ch√≠nh s√°ch th∆∞·ªüng ph·∫°t",
        "x·ª≠ l√Ω vi ph·∫°m n·ªôi quy",
      );
    }

    // PCCC
    if (
      q.includes("ch√°y") ||
      q.includes("chay") ||
      q.includes("n·ªï") ||
      q.includes("no ") ||
      q.includes("pccc") ||
      q.includes("ho·∫£ ho·∫°n") ||
      q.includes("hoa hoan")
    ) {
      keywords.push(
        "ph√≤ng ch√°y ch·ªØa ch√°y",
        "x·ª≠ l√Ω ch√°y n·ªï",
        "an to√†n PCCC",
        "quy tr√¨nh PCCC",
      );
    }

    if (!keywords.length) return question;

    return `${question}\n\nT·ª™ KH√ìA LI√äN QUAN: ${keywords.join(", ")}`;
  }

  // ========== LLM RERANK (B) ==========

  private async rerankDocsWithLLM(
    docs: Document[],
    question: string,
  ): Promise<Document[]> {
    if (!docs.length) return docs;

    // Gi·ªõi h·∫°n s·ªë doc g·ª≠i l√™n LLM cho ƒë·ª° n·∫∑ng
    const MAX_RERANK = 20;
    const slice = docs.slice(0, MAX_RERANK);

    const sys = `
B·∫°n l√† m√¥-ƒëun RERANK t√†i li·ªáu cho tr·ª£ l√Ω n·ªôi b·ªô nh√† h√†ng.

NHI·ªÜM V·ª§:
- Nh·∫≠n v√†o c√¢u h·ªèi + m·ªôt danh s√°ch ƒëo·∫°n t√†i li·ªáu (doc).
- X·∫øp h·∫°ng c√°c doc theo m·ª©c ƒë·ªô LI√äN QUAN ƒë·∫øn c√¢u h·ªèi, t·ª´ cao ƒë·∫øn th·∫•p.
- Ch·ªâ tr·∫£ v·ªÅ DANH S√ÅCH CH·ªà S·ªê, d·∫°ng: "0, 5, 2, 1, 3" (s·ª≠ d·ª•ng ch·ªâ s·ªë ƒë√£ cho).
- Kh√¥ng gi·∫£i th√≠ch, kh√¥ng th√™m t·ª´ n√†o kh√°c.

N·∫øu kh√¥ng ch·∫Øc, c·ª© d·ª±a tr√™n m·ª©c ƒë·ªô g·∫ßn nghƒ©a v·ªõi c√¢u h·ªèi.
Tr·∫£ v·ªÅ √çT NH·∫§T 1 ch·ªâ s·ªë.
`.trim();

    const docsText = slice
      .map((d, i) => {
        const meta = (d as any).metadata || {};
        const src = meta.source || "";
        let txt = (d as any).pageContent || (d as any).page_content || "";
        txt = txt.replace(/^=+\s*FILE:[^\n]*\n/gi, "").trim();
        if (txt.length > 500) {
          txt = txt.slice(0, 500) + " ‚Ä¶";
        }
        return `[#${i}] source=${src}\n${txt}`;
      })
      .join("\n\n---\n\n");

    const usr = `
C√¢u h·ªèi: """${question}"""

DANH S√ÅCH DOC:
${docsText}

H√£y tr·∫£ v·ªÅ danh s√°ch ch·ªâ s·ªë (v√≠ d·ª•: "0, 2, 1, 3").
`.trim();

    const out = await this.llm.chat(sys, usr, 12_000);
    const raw = (out || "").trim();
    if (!raw) return docs;

    // Parse chu·ªói "0, 5, 2, 1"
    const idxs = raw
      .split(/[^0-9]+/)
      .map((x) => x.trim())
      .filter(Boolean)
      .map((x) => Number(x))
      .filter((n) => Number.isInteger(n) && n >= 0 && n < slice.length);

    if (!idxs.length) return docs;

    const reordered: Document[] = [];
    const used = new Set<number>();

    for (const i of idxs) {
      if (!used.has(i)) {
        reordered.push(slice[i]);
        used.add(i);
      }
    }

    // Th√™m c√°c doc c√≤n l·∫°i (n·∫øu LLM kh√¥ng li·ªát k√™ ƒë·ªß)
    slice.forEach((d, i) => {
      if (!used.has(i)) reordered.push(d);
    });

    // N·∫øu docs g·ªëc nhi·ªÅu h∆°n MAX_RERANK ‚Üí n·ªëi ph·∫ßn c√≤n l·∫°i ph√≠a sau
    if (docs.length > MAX_RERANK) {
      reordered.push(...docs.slice(MAX_RERANK));
    }

    return reordered;
  }

 async askWithLangChain(
  question: string,
  opts?: {
    topK?: number;
    role?: "KITCHEN" | "WAITER" | "CASHIER" | "MANAGER" | "ALL";
    scoreThreshold?: number; // t·∫°m ch∆∞a d√πng v√¨ LangChain kh√¥ng tr·∫£ score
  },
) {
  await this.ensureCollection(this.docCollection);
  await this.ensureDocPayloadIndexes();

  const topK = opts?.topK ?? Number(process.env.RAG_TOPK || 40);
  const role = opts?.role;

  const store = await this.getVectorStore();

  // ===== 1) Filter theo role =====
  const must: any[] = [];
  const q = question.toLowerCase();
  let deptRole: RagRole | null = null;

  if (q.includes("b·∫øp") || q.includes("bep") || q.includes("kitchen")) {
    deptRole = "KITCHEN";
  } else if (
    q.includes("ph·ª•c v·ª•") ||
    q.includes("phuc vu") ||
    q.includes("waiter")
  ) {
    deptRole = "WAITER";
  } else if (
    q.includes("thu ng√¢n") ||
    q.includes("thu ngan") ||
    q.includes("cashier")
  ) {
    deptRole = "CASHIER";
  } else if (
    q.includes("qu·∫£n l√Ω") ||
    q.includes("quan ly") ||
    q.includes("manager")
  ) {
    deptRole = "MANAGER";
  }

 let roleFilter: RagRole | null = null;

// ƒëo√°n b·ªô ph·∫≠n theo c√¢u h·ªèi
if (deptRole) {
  roleFilter = deptRole;
} else if (role && role !== "ALL" && role !== "MANAGER") {
  // üëà MANAGER coi nh∆∞ ALL, kh√¥ng filter
  roleFilter = role;
}

if (roleFilter) {
  must.push({
    key: "metadata.role",
    match: { any: [roleFilter, "ALL"] },
  });
}


  const filter = must.length ? { must } : undefined;

  // ===== 2) Query expansion + vector search =====
  const enrichedQuestion = this.buildEnrichedQuestion(question);

  const docs = (await store.similaritySearch(
    enrichedQuestion,
    topK,
    filter,
  )) as Document[];

  this.log.log(
    `[RAG] [LangChain] query="${question}" enriched="${enrichedQuestion}" docs=${docs.length}`,
  );
  docs.forEach((d: any, i) => {
    this.log.log(
      `[RAG] [${i}] src=${d.metadata?.source} idx=${d.metadata?.index} role=${d.metadata?.role}`,
    );
  });

  if (!docs.length) {
    return {
      answer: "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu.",
      sources: [],
    };
  }

  // ===== 3) Rerank b·∫±ng LLM (n·∫øu l·ªói th√¨ gi·ªØ nguy√™n) =====
  let rankedDocs = docs;
  try {
    rankedDocs = await this.rerankDocsWithLLM(docs, question);
  } catch (e: any) {
    this.log.warn(`[RAG] rerankDocsWithLLM error: ${e?.message || e}`);
  }

  // ===== 4) Ch·ªçn doc d√πng l√†m context (gi·ªõi h·∫°n cho g·ªçn) =====
  const MAX_CONTEXT_DOCS = 6;

  // Option: ∆∞u ti√™n c√°c chunk c√πng source v·ªõi doc t·ªët nh·∫•t, nh∆∞ng v·∫´n gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
  const bestSource = (rankedDocs[0] as any).metadata?.source as
    | string
    | undefined;

  let selectedDocs: Document[];
  if (bestSource) {
    const sameSource = rankedDocs.filter(
      (d: any) => d.metadata?.source === bestSource,
    );
    sameSource.sort(
      (a: any, b: any) => (a.metadata?.index ?? 0) - (b.metadata?.index ?? 0),
    );
    selectedDocs = sameSource.slice(0, MAX_CONTEXT_DOCS);
  } else {
    selectedDocs = rankedDocs.slice(0, MAX_CONTEXT_DOCS);
  }

  const context = selectedDocs
    .map((d: any, i) => {
      let txt = d.pageContent ?? d.page_content ?? "";
      txt = String(txt)
        .replace(/^=+\s*FILE:[^\n]*\n/gi, "")
        .trim();
      return `[#${i + 1}] source=${d.metadata?.source ?? ""}\n${txt}`;
    })
    .join("\n\n---\n\n");

  // ===== 5) G·ªçi LLM tr·∫£ l·ªùi d·ª±a tr√™n context =====
  const sys = `
B·∫°n l√† tr·ª£ l√Ω n·ªôi b·ªô c·ªßa nh√† h√†ng.

NHI·ªÜM V·ª§:
- Ch·ªâ d·ª±a v√†o ph·∫ßn "T√†i li·ªáu" ƒë·ªÉ tr·∫£ l·ªùi.
- Tr·∫£ l·ªùi NG·∫ÆN G·ªåN, ƒë√∫ng TR·ªåNG T√ÇM c√¢u h·ªèi.
- N·∫øu c√¢u h·ªèi d·∫°ng "quy tr√¨nh", "c√°c b∆∞·ªõc", "workflow":
  ‚Üí Tr·∫£ l·ªùi theo d·∫°ng:
    1) ...
    2) ...
    3) ...
- Kh√¥ng b·ªãa, kh√¥ng th√™m n·ªôi dung b√™n ngo√†i.
- N·∫øu th·∫≠t s·ª± kh√¥ng c√≥ th√¥ng tin li√™n quan, tr·∫£ l·ªùi ƒë√∫ng 1 c√¢u:
  "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu."

Tr·∫£ l·ªùi ti·∫øng Vi·ªát th√¢n thi·ªán, r√µ r√†ng.
`.trim();

  const usr = `
C√¢u h·ªèi: ${question}

T√†i li·ªáu:
${context || "(tr·ªëng)"}
`.trim();

  // ... sau khi build `context` v√† g·ªçi LLM:

let answer = "";
try {
  answer = (await this.llm.chat(sys, usr, 28_000)) || "";
} catch (e) {
  this.log.warn(
    `[RAG.askWithLangChain] llm.chat error: ${
      e instanceof Error ? e.message : e
    }`,
  );
}

// ===== Fallback th√¥ng minh =====
const hasDocs = rankedDocs.length > 0;
const normAnswer = (answer || "").toLowerCase().normalize("NFC");

// N·∫øu LLM b·∫£o "kh√¥ng t√¨m th·∫•y" nh∆∞ng th·ª±c ra M√åNH c√≥ docs ‚Üí kh√¥ng cho n√≥i c√¢u ƒë√≥
const looksLikeNotFound =
  normAnswer.includes("kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu") ||
  normAnswer.includes("khong tim thay trong tai lieu");

if ((!answer || !answer.trim()) && hasDocs) {
  // LLM im lu√¥n ‚Üí show context
  this.log.warn(
    `[RAG.askWithLangChain] Empty answer but has docs, using context fallback.`,
  );
  answer =
    "Theo t√†i li·ªáu n·ªôi b·ªô, th√¥ng tin li√™n quan nh∆∞ sau:\n\n" + context;
} else if (looksLikeNotFound && hasDocs) {
  // LLM n√≥i "kh√¥ng t√¨m th·∫•y" m√† th·ª±c t·∫ø c√≥ doc ‚Üí override
  this.log.warn(
    `[RAG.askWithLangChain] LLM said 'kh√¥ng t√¨m th·∫•y' but docs exist, overriding with context.`,
  );
  answer =
    "Theo t√†i li·ªáu n·ªôi b·ªô, h·ªá th·ªëng t√¨m ƒë∆∞·ª£c c√°c n·ªôi dung sau (b·∫°n xem v√† √°p d·ª•ng ph√π h·ª£p):\n\n" +
    context;
}

// N·∫øu th·ª±c s·ª± KH√îNG c√≥ docs ‚Üí m·ªõi cho n√≥i "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu."
if (!answer?.trim() && !hasDocs) {
  answer = "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu.";
}

return {
  answer: answer.trim(),
  sources: selectedDocs.map((d: any, i) => ({
    index: i + 1,
    source: d.metadata?.source,
    role: d.metadata?.role,
  })),
};
}
// src/modules/rag/rag.service.ts

async deleteDocsBySource(source: string) {
  await this.ensureCollection(this.docCollection);
  try {
    await this.qdrant.delete(this.docCollection as any, {
      filter: {
        must: [
          {
            key: "metadata.source",
            match: { value: source },
          },
        ],
      },
    } as any);
    this.log.log(`[RAG] Deleted docs for source=${source}`);
  } catch (e: any) {
    this.log.warn(
      `[RAG] deleteDocsBySource(${source}) error: ${e?.message || e}`,
    );
  }
}

}
