import { Injectable, Logger } from "@nestjs/common";
import { QdrantClient } from "@qdrant/js-client-rest";
import { LlmGateway } from "../ai/llm.gateway";
import { GatewayEmbeddings } from "./langchain-embeddings";
import { QdrantVectorStore } from "@langchain/qdrant";
import { Document } from "@langchain/core/documents";

export type RagHit = { text: string; score?: number; source?: string; absPath?: string; index?: number };

@Injectable()
export class RagService {
  private readonly log = new Logger("RAG");
  private readonly qdrant = new QdrantClient({
    url: process.env.QDRANT_URL || "http://localhost:6333",
    apiKey: process.env.QDRANT_API_KEY || undefined, // <- th√™m d√≤ng n√†y
  });
  // collection schema
  private readonly schemaCollection =
    process.env.QDRANT_SCHEMA_COLLECTION || "restaurant_schema";

  // collection SOP/docs
  private readonly docCollection =
    process.env.QDRANT_DOC_COLLECTION || "restaurant_docs";
  constructor(private readonly llm: LlmGateway) {}

  private async embed(input: string | string[]) {
    return this.llm.embed(input);
  }

  private async getEmbedDim(): Promise<number> {
    const v = await this.embed("probe");
    const arr = Array.isArray(v) && Array.isArray((v as any)[0]) ? (v as number[][])[0] : (v as number[]);
    if (!arr?.length) throw new Error("Cannot infer embedding dimension");
    return arr.length; // e.g., 768 for text-embedding-004
  }

  private async ensureCollection(collection: string): Promise<number> {
  const dim = await this.getEmbedDim();

  try {
    const info: any = await this.qdrant.getCollection(collection as any);
    const currentDim =
      info?.result?.config?.params?.vectors?.size ??
      info?.config?.params?.vectors?.size ??
      info?.result?.config?.params?.vectors?.["float"]?.size ??
      null;

    if (currentDim && currentDim !== dim) {
      if (String(process.env.RAG_RESET || "0") !== "1") {
        throw new Error(
          `'${collection}' size=${currentDim}, embed=${dim}. Set RAG_RESET=1 to recreate.`,
        );
      }
      this.log.warn(`Recreating '${collection}' with size=${dim} ...`);
      await this.qdrant.deleteCollection(collection as any);
    }
  } catch (_) {}

  try {
    await this.qdrant.createCollection(collection as any, {
      vectors: { size: dim, distance: "Cosine" },
    } as any);
  } catch (e: any) {
    const conflict = e?.status === 409 || /exists/i.test(e?.message || "");
    if (!conflict) throw e;
  }

  return dim;
}


async upsertSchemaChunk(ch: { id: string; text: string; meta?: any }) {
  await this.ensureCollection(this.schemaCollection);
  const v = await this.embed(ch.text);
  const vector = this.normalizeVector(v);

  const meta = ch.meta || {};

  await this.qdrant.upsert(this.schemaCollection, {
    wait: true,
    points: [
      {
        id: ch.id,
        vector,
        payload: {
          // gi·ªØ layout c≈©
          text: ch.text,
          ...meta,
          // layout chu·∫©n cho LangChain
          page_content: ch.text,
          pageContent: ch.text,        // th√™m lu√¥n cho ch·∫Øc
          metadata: { ...meta },
        },
      },
    ],
  });
}

// RagService

async upsertDocChunk(ch: { id: string; text: string; meta?: any }) {
  await this.ensureCollection(this.docCollection);
  await this.ensureDocPayloadIndexes();

  const v = await this.embed(ch.text);
  const vector = this.normalizeVector(v);

  await this.qdrant.upsert(this.docCollection as any, {
    wait: true,
    points: [
      {
        id: ch.id,
        vector,
        payload: {
          // üëá ƒë√∫ng chu·∫©n LangChain
          page_content: ch.text,
          metadata: {
            ...(ch.meta || {}),
          },
        },
      },
    ],
  });
}



private normalizeVector(v: any): number[] {
  // embed tr·∫£ v·ªÅ [number[]] ho·∫∑c number[]
  if (Array.isArray(v)) {
    if (Array.isArray(v[0])) {
      return v[0] as number[];
    }
    return v as number[];
  }
  throw new Error("Embedding vector is invalid");
}

  async searchDocs(
  question: string,
  topK = 4,
  scoreThreshold = 0.18,
  sourceFilter?: string,        // üëà th√™m
) {
  await this.ensureCollection(this.docCollection);
    await this.ensureDocPayloadIndexes();
  const v = await this.embed(question);
  const vector = this.normalizeVector(v);

  const filter = sourceFilter
    ? {
        must: [
          {
            key: "metadata.source", 
            match: { value: sourceFilter },
          },
        ],
      }
    : undefined;

  const r = await this.qdrant.search(this.docCollection as any, {
    vector,
    limit: topK,
    with_payload: true,
    score_threshold: scoreThreshold,
    filter,                     // üëà truy·ªÅn filter v√†o
  });

  return (r || []).sort((a, b) => (b.score ?? 0) - (a.score ?? 0));
}



  /** PUBLIC: cho AiService ‚Äì tr·∫£ danh s√°ch hit g·ªçn */
 async query(
  question: string,
  topK = Number(process.env.RAG_TOPK || 4),
): Promise<RagHit[]> {
  const q = question.toLowerCase();

  let sourceFilter: string | undefined;
  if (q.includes("b·∫øp")) {
    sourceFilter = "sop_bep.txt";
  } else if (q.includes("ph·ª•c v·ª•")) {
    sourceFilter = "sop_phuc_vu.txt";
  } else if (q.includes("thu ng√¢n") || q.includes("thu ng√¢n")) {
    sourceFilter = "sop_thu_ngan.txt";
  } else if (q.includes("qu·∫£n l√Ω")) {
    sourceFilter = "sop_quan_ly.txt";
  }

  const hits = await this.searchDocs(
    question,
    topK,
    Number(process.env.RAG_SCORE_THRESHOLD || 0.18),
    sourceFilter,
  );

  return (hits || []).map((h: any) => ({
    text: h.payload?.text || "",
    score: h.score,
    source: h.payload?.source,
    absPath: h.payload?.absPath,
    index: h.payload?.index,
  }));
}


  /** N·∫øu mu·ªën RAG t·ª± t·ªïng h·ª£p tr·∫£ l·ªùi (kh√¥ng b·∫Øt bu·ªôc) */
 /** N·∫øu mu·ªën RAG t·ª± t·ªïng h·ª£p tr·∫£ l·ªùi (kh√¥ng b·∫Øt bu·ªôc) */
async ask(question: string, topK = Number(process.env.RAG_TOPK || 4)) {
  const hits = await this.query(question, topK);

  // Gh√©p context t·ª´ t√†i li·ªáu
  const context = hits
    .map(
      (h, i) =>
        `[${i + 1}] (${(h.score || 0).toFixed(3)}) ${h.source || ""}\n${h.text}`,
    )
    .join("\n\n---\n\n");

 const sys = `
B·∫°n l√† tr·ª£ l√Ω n·ªôi b·ªô c·ªßa nh√† h√†ng.

NHI·ªÜM V·ª§:
- Ch·ªâ d·ª±a v√†o ph·∫ßn "T√†i li·ªáu" b√™n d∆∞·ªõi ƒë·ªÉ tr·∫£ l·ªùi.
- Tr·∫£ l·ªùi NG·∫ÆN G·ªåN, ƒë√∫ng TR·ªåNG T√ÇM c√¢u h·ªèi.
- N·∫øu c√¢u h·ªèi d·∫°ng "quy tr√¨nh", "c√°c b∆∞·ªõc", "workflow":
  ‚Üí Ch·ªâ tr√≠ch ƒë√∫ng c√°c b∆∞·ªõc li√™n quan, theo d·∫°ng:
    1) ...
    2) ...
    3) ...
- Kh√¥ng ƒë∆∞·ª£c ƒë∆∞a n·ªôi dung t·ª´ c√°c ph·∫ßn SOP kh√°c n·∫øu kh√¥ng li√™n quan
  (vd: h·ªèi quy tr√¨nh ch·∫ø bi·∫øn m√≥n ‚Üí KH√îNG ƒë∆∞·ª£c tr·∫£ l·ªùi v·ªÅ h·ªßy m√≥n, ƒë·ªïi m√≥n, h·∫øt nguy√™n li·ªáu‚Ä¶).
- N·∫øu t√†i li·ªáu c√≥ 1 ph·∫ßn li√™n quan, ph·∫£i d√πng ph·∫ßn ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi,
  kh√¥ng ƒë∆∞·ª£c tr·∫£ "Kh√¥ng t√¨m th·∫•y" khi trong t√†i li·ªáu c√≥ th√¥ng tin ƒë√∫ng ch·ªß ƒë·ªÅ.
- Ch·ªâ tr·∫£ ƒë√∫ng c√¢u: "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu."
  khi th·∫≠t s·ª± kh√¥ng c√≥ th√¥ng tin n√†o li√™n quan.

Tr·∫£ l·ªùi ti·∫øng Vi·ªát.
`.trim();

const usr = `C√¢u h·ªèi: ${question}\n\nT√†i li·ªáu:\n${context || "(tr·ªëng)"}`;

  let answer = "";
  try {
    answer = (await this.llm.chat(sys, usr, 28000)) || "";
  } catch (e) {
    this.log.warn(`[RAG.ask] llm.chat error: ${e instanceof Error ? e.message : e}`);
  }

  // üîπ N·∫øu LLM KH√îNG tr·∫£ l·ªùi nh∆∞ng V·∫™N C√ì hits ‚Üí fallback sang tr·∫£ context th√¥
  if ((!answer || !answer.trim()) && hits.length > 0) {
    this.log.warn(
      `[RAG.ask] LLM kh√¥ng tr·∫£ l·ªùi, d√πng fallback t·ª´ context. hits=${hits.length}`,
    );
    answer =
      "D∆∞·ªõi ƒë√¢y l√† n·ªôi dung t√†i li·ªáu li√™n quan m√† h·ªá th·ªëng t√¨m ƒë∆∞·ª£c:\n\n" +
      context;
  }

  // üîπ N·∫øu kh√¥ng c√≥ hits n√†o ‚Üí cho ph√©p tr·∫£ "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu."
  if ((!answer || !answer.trim()) && hits.length === 0) {
    answer = "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu.";
  }

  return {
    answer: answer.trim(),
    sources: hits.map((h, i) => ({
      index: i + 1,
      score: h.score,
      source: h.source,
    })),
  };
}
  // üî• D√πng cho script ingest ‚Äì x√≥a to√†n b·ªô ƒëi·ªÉm trong Qdrant r·ªìi t·∫°o l·∫°i
private async ensureDocPayloadIndexes() {
  // index cho metadata.role
  try {
    await this.qdrant.createPayloadIndex(this.docCollection as any, {
      field_name: "metadata.role",
      field_schema: "keyword",
    } as any);
    this.log.log("[RAG] Created payload index for metadata.role");
  } catch (e: any) {
    if (!/already exists/i.test(e?.message || "")) {
      this.log.warn(`[RAG] createPayloadIndex(metadata.role) error: ${e?.message || e}`);
    }
  }

  // OPTIONAL: index cho metadata.source
  try {
    await this.qdrant.createPayloadIndex(this.docCollection as any, {
      field_name: "metadata.source",
      field_schema: "keyword",
    } as any);
    this.log.log("[RAG] Created payload index for metadata.source");
  } catch (e: any) {
    if (!/already exists/i.test(e?.message || "")) {
      this.log.warn(`[RAG] createPayloadIndex(metadata.source) error: ${e?.message || e}`);
    }
  }
}





  async resetDocCollection() {
    this.log.warn(`[RAG] Deleting collection ${this.docCollection} ...`);
    try {
      await this.qdrant.deleteCollection(this.docCollection as any);
    } catch (e: any) {
      this.log.warn(
        `[RAG] deleteCollection(doc) error: ${e?.message || e}`,
      );
    }
    // t·∫°o l·∫°i collection r·ªóng v·ªõi ƒë√∫ng vector dim
    await this.ensureCollection(this.docCollection);
    this.log.warn(`[RAG] Doc collection recreated.`);
  }

  async resetSchemaCollection() {
    this.log.warn(`[RAG] Deleting collection ${this.schemaCollection} ...`);
    try {
      await this.qdrant.deleteCollection(this.schemaCollection as any);
    } catch (e: any) {
      this.log.warn(
        `[RAG] deleteCollection(schema) error: ${e?.message || e}`,
      );
    }
    await this.ensureCollection(this.schemaCollection);
    this.log.warn(`[RAG] Schema collection recreated.`);
  }




   private lcEmbeddings?: GatewayEmbeddings;
  private lcVectorStore?: QdrantVectorStore;

private async getVectorStore() {
  if (this.lcVectorStore) return this.lcVectorStore;

  this.lcEmbeddings = new GatewayEmbeddings(this.llm);

  this.lcVectorStore = await QdrantVectorStore.fromExistingCollection(
    this.lcEmbeddings,
    {
      url: process.env.QDRANT_URL || "http://localhost:6333",
      apiKey: process.env.QDRANT_API_KEY || undefined,
      collectionName: this.docCollection,

      // üëá khai b√°o ƒë√∫ng key ƒë√£ d√πng khi upsert
      contentPayloadKey: "page_content",
      metadataPayloadKey: "metadata",
    },
  );

  return this.lcVectorStore;
}

  /** RAG d√πng LangChain + l·ªçc theo role (optional) */
  // import ·ªü ƒë·∫ßu file


// ...


async askWithLangChain(
  question: string,
  opts?: {
    topK?: number;
    role?: "KITCHEN" | "WAITER" | "CASHIER" | "MANAGER" | "ALL";
    scoreThreshold?: number;
  },
) {
  await this.ensureCollection(this.docCollection);
  await this.ensureDocPayloadIndexes();

  const topK = opts?.topK ?? Number(process.env.RAG_TOPK || 8);
  const scoreThreshold =
    opts?.scoreThreshold ?? Number(process.env.RAG_SCORE_THRESHOLD || 0.05);
  const role = opts?.role;

  const store = await this.getVectorStore();

  const must: any[] = [];
  const q = question.toLowerCase();

  // 1) L·ªçc theo role (tr·ª´ MANAGER, MANAGER ƒë·ªçc ƒë∆∞·ª£c h·∫øt)
  if (role && role !== "ALL" && role !== "MANAGER") {
    must.push({
      key: "metadata.role",
      match: { any: [role, "ALL"] },
    });
  }

  // 2) L·ªçc th√™m theo ngu·ªìn SOP theo t·ª´ kho√° trong c√¢u h·ªèi
  const sources: string[] = [];

  if (q.includes("thu ng√¢n") || q.includes("thu ngan") || q.includes("cashier")) {
    sources.push("sop_thu_ngan.txt");
  }
  if (q.includes("ph·ª•c v·ª•") || q.includes("phuc vu") || q.includes("ph·ª•c v·ª•")) {
    sources.push("sop_phuc_vu.txt");
  }
  if (q.includes("b·∫øp") || q.includes("kitchen")) {
    sources.push("sop_bep.txt");
  }
  if (q.includes("qu·∫£n l√Ω") || q.includes("quan ly") || q.includes("manager")) {
    sources.push("sop_quan_ly.txt");
  }

  // lu√¥n cho ph√©p SOP t·ªïng qu√°t n·∫øu ƒë√£ match b·ªô ph·∫≠n n√†o ƒë√≥
  if (sources.length > 0) {
    sources.push("sop_tong_quat.txt");
    must.push({
      key: "metadata.source",
      match: { any: sources },
    });
  }

  const filter = must.length ? { must } : undefined;

  const docs = (await store.similaritySearch(
    question,
    topK,
    filter,
  )) as Document[];

  const filtered = docs.filter((d: any) => {
    const s =
      typeof d.metadata?.score === "number"
        ? d.metadata.score
        : typeof d.score === "number"
        ? d.score
        : undefined;
    if (typeof s !== "number") return true;
    return s >= scoreThreshold;
  });

  this.log.log(
    `[RAG] [LangChain] query="${question}" docs=${docs.length}, filtered=${filtered.length}`,
  );
  filtered.forEach((d, i) => {
    this.log.log(
      `[RAG] [${i}] src=${d.metadata?.source} idx=${d.metadata?.index} role=${d.metadata?.role}`,
    );
  });

  const context = filtered
    .map(
      (d) =>
        `=== ${d.metadata?.source ?? ""} (idx=${d.metadata?.index}) ===\n${d.pageContent}`,
    )
    .join("\n\n");

  const sysPrompt = `
B·∫°n l√† tr·ª£ l√Ω n·ªôi b·ªô c·ªßa nh√† h√†ng.
Ch·ªâ d√πng n·ªôi dung trong ph·∫ßn T√ÄI LI·ªÜU d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi.
N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, tr·∫£ l·ªùi ƒë√∫ng c√¢u: "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu."

T√ÄI LI·ªÜU:
${context || "(tr·ªëng)"}
  `.trim();

 const rawAnswer = await this.llm.chat(sysPrompt, question, 30_000);
let answer = (rawAnswer || "").trim();

if (!answer || !answer.trim()) {
  if (filtered.length === 0) {
    answer = "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu.";
  } else {
    // kh√¥ng x·∫£ context n·ªØa, n√≥i nh·∫π nh√†ng th√¥i
    answer =
      "M√¨nh ƒë√£ t√¨m ƒë∆∞·ª£c m·ªôt s·ªë ƒëo·∫°n trong SOP li√™n quan, nh∆∞ng ch∆∞a t√≥m t·∫Øt ƒë∆∞·ª£c r√µ r√†ng. B·∫°n c√≥ th·ªÉ m·ªü tr·ª±c ti·∫øp t√†i li·ªáu ho·∫∑c h·ªèi c·ª• th·ªÉ h∆°n nh√©.";
  }
}



  return {
    answer: (answer || "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu.").trim(),
    sources: filtered.map((d: any) => ({
      source: d.metadata?.source,
      index: d.metadata?.index,
      score: d.metadata?.score,
    })),
  };
}



}


